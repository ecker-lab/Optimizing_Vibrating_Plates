{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ0XVazsDLEM"
      },
      "source": [
        "## Guided Flow Matching Design Optimization Example Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTNLHg1A4hTJ"
      },
      "source": [
        "Thank you for your interest in our flow matching based design optimization method for minimizing structural vibrations in plates!\n",
        "\n",
        "With this notebook and google colab, you can try out the pipeline for optimizing novel plates for your own objective functions with no setup required. Of course, this notebook can also be run on a local machine with gpu access. However, you might need to install some additional packages, as we are only installing those missing on colab.\n",
        "\n",
        "You need to be signed in with your google account. Please also make sure that you are connected to a gpu runtime by by selecting 'runtime' change runtime to e.g. T4 GPU. The following code snippet will show a table with gpu information if you are connnected to a gpu runtime. To run the code snippet, simply click on the left edge. or press (Ctrl + enter) after selecting it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI42xeR55Qsl"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCl6z0uNseOV"
      },
      "source": [
        "The following two code snippets are necessary to set up the environment and download the model weights. Simply run them before continuing. It takes around 2 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SYchH0wLXqx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# install environment\n",
        "!pip install \\\n",
        "    munch==4.0 \\\n",
        "    wandb \\\n",
        "    h5py==3.12 \\\n",
        "    hdf5plugin==4.2 \\\n",
        "    flow_matching \\\n",
        "    torchinterp1d==1.1\n",
        "!pip install git+https://github.com/JanvDelden/template.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following downloads depend on the download speed of google colab, which can be quite slow sometimes and take around 2 minutes. In total, around 150 MB are downloaded."
      ],
      "metadata": {
        "id": "faCICy7RZx95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.goettingen-research-online.de/api/access/datafile/125255 -O regression_model.ckpt\n",
        "!wget https://data.goettingen-research-online.de/api/access/datafile/125254 -O flow_matching_model.ckpt\n",
        "!wget https://data.goettingen-research-online.de/api/access/datafile/125124 -O moments_dict.pt\n",
        "\n",
        "!git clone https://github.com/ecker-lab/Optimizing_Vibrating_Plates.git\n",
        "%cd Optimizing_Vibrating_Plates\n",
        "%pip install -e ."
      ],
      "metadata": {
        "id": "wsePEkkVx1BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8mJVagRvlI"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INqgac0r0KQJ"
      },
      "source": [
        "We first import the required functions and set up the flow matching as well as the regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from plate_optim.flow_matching.models.unet import UNetModel\n",
        "from plate_optim.regression.regression_model import get_net, get_mean_from_velocity_field\n",
        "from plate_optim.utils.data import get_moments\n",
        "from plate_optim.utils.guidance import _callable_constructor, get_loss_fn\n",
        "from flow_matching.solver import ODESolver\n",
        "\n",
        "\n",
        "flow_matching_path='/content/flow_matching_model.ckpt'\n",
        "regression_path='/content/regression_model.ckpt'\n",
        "moments_dict_path='/content/moments_dict.pt'\n",
        "\n",
        "\n",
        "# load flow matching model\n",
        "config = json.load(open('/content/Optimizing_Vibrating_Plates/configs/flow_matching_config.json'))\n",
        "model = UNetModel(**config).cuda()\n",
        "model.load_state_dict(torch.load(flow_matching_path)['model_state_dict'])\n",
        "\n",
        "# load regression model\n",
        "regression_model = get_net(conditional=True, len_conditional=3, scaling_factor=32).cuda()\n",
        "regression_model.load_state_dict(torch.load(regression_path)['model_state_dict'])\n",
        "regression_model.eval(), model.eval()\n",
        "\n",
        "# load mean and standard deviation of data\n",
        "out_mean, out_std, field_mean, field_std = get_moments(moments_dict_path=moments_dict_path, device='cuda')\n",
        "mean_conditional_param = [50, 0.5, 0.5] # Boundary condition, force_position x, force_position y\n",
        "std_conditional_param = [28.8675, 0.173205,  0.173205]\n",
        "\n",
        "# specify general variables\n",
        "device = 'cuda'\n",
        "resolution = [96, 128]\n",
        "n_samples = 4"
      ],
      "metadata": {
        "id": "WiGKdHqOvGb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we specify the physical parameters of the optimized plates as well as the optimization range for the frequencies. Based on this we construct an objective function and build our velocity model from the objective function and the flow matching model. Feel free to change e.g. the parameters min_freq and max_freq, that specify the optimization range between 1 and 300."
      ],
      "metadata": {
        "id": "0Gu86uKI_eTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify objective function\n",
        "min_freq, max_freq = 100, 200\n",
        "phy_para = [0, 0.34444444444444444, 0.35] # 0, 0.31 / 0.9, 0.21 / 0.6\n",
        "\n",
        "frequencies = torch.linspace(-1.0, 1, 300).cuda()[min_freq:max_freq].unsqueeze(0).repeat(n_samples, 1)\n",
        "condition_norm = torch.tensor([phy_para], device=device, dtype=torch.float32).repeat(n_samples, 1)\n",
        "condition = (condition_norm -  torch.tensor(mean_conditional_param).float().cuda().unsqueeze(0))\\\n",
        "        / torch.tensor(std_conditional_param).float().unsqueeze(0).cuda()\n",
        "loss_fn = get_loss_fn(regression_model, condition, frequencies, field_mean, field_std)\n",
        "\n",
        "# build velocity model\n",
        "velocity_model = _callable_constructor(model, loss_fn, save_path='/content/optimization')"
      ],
      "metadata": {
        "id": "oxqniHCl3nsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can solve the constructed ODE starting from random noise x_0. In this case, we use the euler method and in total 20 steps. The alpha parameter, that controls the relative strength of the guidance pushing towards minimizing the objective function, is set to 1."
      ],
      "metadata": {
        "id": "wOgyUlVpAFRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run solver starting from random noise x_0\n",
        "solver = ODESolver(velocity_model=velocity_model)\n",
        "x_0 = torch.randn([n_samples, 1, *resolution], dtype=torch.float32, device=device)\n",
        "samples = solver.sample(\n",
        "    time_grid=torch.linspace(0, 1, int(1 / 0.05) + 1),\n",
        "    x_init=x_0,\n",
        "    method='euler',\n",
        "    step_size=0.05,\n",
        "    alpha=1,\n",
        "    norm_grad=True,\n",
        "    return_intermediates=True,\n",
        ")\n",
        "final_samples = samples[-1].detach().cpu()\n"
      ],
      "metadata": {
        "id": "TP8kho91vmh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can take a look at our generated beading patterns and their dynamic response as evaluated by the regression model. The results differ for different sampled x_0 and changed optimization parameters."
      ],
      "metadata": {
        "id": "akh84TGnBPjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "fig, ax = plt.subplots(2,  min(n_samples, 8), figsize=(10, 4))\n",
        "\n",
        "with torch.no_grad():\n",
        "    frequencies_full = torch.linspace(-1.0, 1, 300).cuda().unsqueeze(0).repeat(n_samples, 1)\n",
        "    pred = regression_model(final_samples.cuda(), condition, frequencies_full)\n",
        "    prediction = get_mean_from_velocity_field(pred, field_mean, field_std, frequencies_full)\n",
        "\n",
        "for i in range(min(n_samples, 8)):\n",
        "    ax[0, i].imshow(final_samples[i].cpu().numpy().squeeze()[::-1], cmap='gray')\n",
        "    ax[0, i].plot(condition_norm[0, 1].cpu() * 128, (1-condition_norm[0, 2].cpu()) * 96,'x', color='red', markersize=4.5, markeredgewidth=1.5)\n",
        "    ax[0, i].axis('off')\n",
        "\n",
        "\n",
        "    frequencies_ = torch.arange(1, 301)\n",
        "    ax[1, i].plot(frequencies_, prediction[i].cpu(), lw=0.8, color='grey', ls='--')\n",
        "    ax[1, i].set_ylim(-25, 65)\n",
        "    ax[1, i].grid(alpha=0.3, lw=0.5)\n",
        "    sns.despine(ax=ax[1, i], offset=5)\n",
        "    ax[1, i].set_title(f'{i}: {prediction[i][min_freq:max_freq].cpu().mean().item():.3f}')\n",
        "    ax[1, i].set_xlabel('Velocity (dB)')\n",
        "    ax[1, i].set_ylabel('Frequency (Hz)')\n",
        "    plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "y-3G2-bCvrf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the optimization process reproducing one of the plots from our paper."
      ],
      "metadata": {
        "id": "I96rZxsIDf1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "sample_id = torch.argmin(prediction[:, min_freq:max_freq].mean(dim=1))\n",
        "files = os.listdir('/content/optimization')\n",
        "pattern = re.compile(r'^(grad|v_flow)_(\\d+\\.\\d+)\\.pt$')\n",
        "\n",
        "# Collect (value, filename) pairs for each category\n",
        "groups = {'grad': [], 'v_flow': []}\n",
        "for fname in files:\n",
        "    m = pattern.match(fname)\n",
        "    if not m:\n",
        "        continue\n",
        "    prefix, num_str = m.group(1), m.group(2)\n",
        "    num = float(num_str)\n",
        "    groups[prefix].append((num, fname))\n",
        "\n",
        "# Sort by the numeric suffix and load data\n",
        "for key in groups:\n",
        "    groups[key].sort(key=lambda pair: pair[0])\n",
        "grad_suffixes  = [num for num, _ in groups['grad']]\n",
        "vflow_suffixes = [num for num, _ in groups['v_flow']]\n",
        "grad_tensors  = [torch.load(os.path.join('/content/optimization', fname)) for _, fname in groups['grad']]\n",
        "vflow_tensors = [torch.load(os.path.join('/content/optimization', fname)) for _, fname in groups['v_flow']]\n",
        "grads   = torch.cat(grad_tensors,  dim=1)\n",
        "v_flows = torch.cat(vflow_tensors, dim=1)"
      ],
      "metadata": {
        "id": "IYFwRoz6Cg9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# produce the actual plot\n",
        "n_plots = 11\n",
        "intermediate_sample = samples[:,sample_id,0].cpu().numpy()[:, ::-1]\n",
        "grad = grads[sample_id].cpu().numpy()[:, ::-1]\n",
        "v_flow = v_flows[sample_id].cpu().numpy()[:, ::-1]\n",
        "\n",
        "idx = torch.linspace(0, len(intermediate_sample)- 1, steps=n_plots).round().long()\n",
        "fig, axes = plt.subplots(4, n_plots, figsize=(6.75*1.5, 2*1.5), gridspec_kw={'wspace': 0, 'hspace': 0})\n",
        "\n",
        "# turn off axes for images-only rows\n",
        "for ax in axes[:3].flat:\n",
        "    ax.axis('off')\n",
        "\n",
        "for col, id in enumerate(idx):\n",
        "    t = id/(len(intermediate_sample)-1)\n",
        "    axes[0, col].imshow(intermediate_sample[id], cmap='gray')\n",
        "    axes[0, col].plot(condition_norm[sample_id, 1].cpu() * 128, (1-condition_norm[sample_id, 2].cpu()) * 96,'x',\n",
        "                       color='red', markersize=4.5, markeredgewidth=1.5)\n",
        "    axes[0, col].set_title(f\"t={t:.2f}\", pad=2)\n",
        "    if t < 0.75:\n",
        "        vmax_scale = max(np.abs(grad[id].min()), np.abs(grad[id].max()))\n",
        "        axes[1, col].imshow(grad[id], cmap='gray', vmin=-vmax_scale, vmax=vmax_scale)\n",
        "    if t < 1:\n",
        "        axes[2, col].imshow(v_flow[id], cmap='gray')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inp = torch.from_numpy(intermediate_sample[id][::-1].copy()).view(1,1,96,128).cuda()\n",
        "        pred = regression_model(inp, condition[:1], frequencies_full[:1])\n",
        "        prediction = get_mean_from_velocity_field(pred, field_mean, field_std, frequencies_full[:1])\n",
        "\n",
        "    ax3 = axes[3, col]\n",
        "    ax3.plot(frequencies_.cpu(), prediction[0].cpu(), lw=0.8, color='grey', ls='--')\n",
        "    ax3.set_ylim(-25, 65)\n",
        "    ax3.set_xticklabels([])\n",
        "    ax3.grid(alpha=0.3, lw=0.5)\n",
        "    ax3.set_yticklabels([])\n",
        "    ax3.tick_params(axis='y', length=0)\n",
        "    ax3.tick_params(axis='x', length=0)\n",
        "    sns.despine(ax=ax3, left=True, bottom=True, offset=5)\n",
        "\n",
        "fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n"
      ],
      "metadata": {
        "id": "x3Qbcnk-CikV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first row in the above plot shows x_t, the second the gradient signal from the objective function, and the third row the prediction from the flow matching model. The last row shows the predicted dynamic response given x_t.\n",
        "\n",
        "Next, lets turn this plot into a video."
      ],
      "metadata": {
        "id": "kVgoUzm7I_q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Prepare the three frame‐stacks\n",
        "intermediates_best = samples[:, sample_id, 0].cpu().numpy()\n",
        "\n",
        "frames1 = intermediates_best[:, ::-1]\n",
        "frames2 = grad\n",
        "frames3 = v_flow\n",
        "frames2 = np.pad(frames2, ((0, frames1.shape[0] - frames2.shape[0]), (0, 0), (0, 0)), mode='edge')\n",
        "frames3 = np.pad(frames3, ((0, frames1.shape[0] - frames3.shape[0]), (0, 0), (0, 0)), mode='edge')\n",
        "\n",
        "n_frames = frames1.shape[0]\n",
        "\n",
        "# Set up a wide figure with 3 subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(1.28*4*3, 0.96*4))\n",
        "ims = []\n",
        "for ax, frames in zip(axes, (frames1, frames2, frames3)):\n",
        "    im = ax.imshow(frames[0], cmap=\"gray\", animated=True)\n",
        "    ax.plot(\n",
        "    condition_norm[sample_id, 1].cpu() * 128,\n",
        "    (1-condition_norm[sample_id, 2].cpu()) * 96,\n",
        "    'x', color='red', markersize=8.5, markeredgewidth=2.5\n",
        "    )\n",
        "    ax.axis(\"off\")\n",
        "    ims.append(im)\n",
        "\n",
        "def update(i):\n",
        "    vmin, vmax = frames1[i].min(), frames1[i].max(); ims[0].set_clim(vmin, vmax)\n",
        "    for im, frames in zip(ims, (frames1, frames2, frames3)):\n",
        "        im.set_array(frames[i])\n",
        "    return ims\n",
        "\n",
        "\n",
        "ani = FuncAnimation(fig, update, frames=n_frames, interval=500, blit=True)\n",
        "fig.tight_layout(pad=0)\n",
        "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "video_path = f\"/content/combined_{sample_id}.mp4\"\n",
        "writer = FFMpegWriter(fps=1)\n",
        "ani.save(video_path, writer=writer)\n",
        "\n",
        "plt.close(fig)\n",
        "display(HTML(ani.to_jshtml()))\n",
        "print(f\"Saved combined video to: {video_path}\")"
      ],
      "metadata": {
        "id": "J5bEvVEjEPwj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}